<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=430, initial-scale=1.0">
    <title>Object Detection with Camera Control</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            background-color: #f8f9fa; 
            text-align: center; 
            margin: 0;
            padding: 0;
        }
        .container {
            position: relative;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding-top: 20px;
        }
        h1 { font-size: 22px; margin: 10px 0; }
        .video-container { 
            position: relative; 
            width: 100%;
            max-width: 430px;
            height: auto;
        }
        video, canvas { 
            width: 100%; 
            max-width: 430px;
            border-radius: 20px;
            position: fixed;
            top: 50%;
            transform: translateY(-50%);
        }
        #canvas { top: 0; left: 0; z-index: 10; }
        #result { font-size: 18px; margin: 10px 0; font-weight: bold; }
        button { 
            padding: 10px 20px; 
            margin: 10px; 
            border: none; 
            border-radius: 5px; 
            font-size: 16px; 
            cursor: pointer; 
        }
        .btn-switch { background-color: #007AFF; color: white; }
        .btn-toggle { background-color: #FF3B30; color: white; }
        table { 
            width: 100%; 
            margin-top: 20px; 
            border-collapse: collapse; 
            background: white; 
            border-radius: 10px;
            margin-bottom: 30px;
        }
        th, td { 
            padding: 8px; 
            text-align: center; 
            border-bottom: 1px solid #ddd; 
        }
        th { background-color: #007AFF; color: white; }
        .thumbnail { 
            width: 50px; 
            height: 50px; 
            object-fit: cover; 
            border-radius: 5px; 
            cursor: pointer;
        }
        .log-container { margin-top: 100px; }

        footer {
            position: absolute;
            bottom: 0;
            width: 100%;
            background-color: #007AFF;
            color: white;
            padding: 10px 0;
            text-align: center;
            font-size: 14px;
        }
        footer a {
            color: #ffd700;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Object Detection</h1>
        <button class="btn-switch" onclick="switchCamera()">üîÑ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á</button>
        <button class="btn-toggle" onclick="toggleCamera()">üî¥ ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á</button>

        <div class="video-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
        </div>

        <div class="log-container">
            <h2>Detection Log</h2>
            <table>
                <thead>
                    <tr>
                        <th>#</th>
                        <th>Image</th>
                        <th>Object</th>
                        <th>Confidence</th>
                        <th>Time</th>
                    </tr>
                </thead>
                <tbody id="logTable"></tbody>
            </table>
        </div>
    </div>

    <footer>
        <p>‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ <a href="https://krunidblogger.blogspot.com/" target="_blank">‡∏Ñ‡∏£‡∏π‡∏ô‡∏¥‡∏î ‡∏®‡∏¥‡∏©‡∏¢‡πå‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡πÄ‡∏™‡∏∑‡∏≠</a> | ‡∏™‡∏á‡∏ß‡∏ô‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2568</p>
    </footer>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const resultText = document.getElementById('result');
        const logTable = document.getElementById('logTable');
        let model = null;
        let currentStream = null;
        let useFrontCamera = true;
        let detectionCount = 0;
        let cameraActive = false;

        async function setupCamera() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
            const constraints = {
                video: { 
                    facingMode: useFrontCamera ? "user" : "environment",
                    width: 430, height: 932
                }
            };
            currentStream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = currentStream;
        }

        function switchCamera() {
            useFrontCamera = !useFrontCamera;
            if (cameraActive) setupCamera();  // Only switch if camera is active
        }

        async function loadModel() {
            model = await cocoSsd.load();
            console.log("Model Loaded!");
        }

        function captureImage() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            return canvas.toDataURL("image/png");
        }

        function logDetection(object, confidence, imageUrl) {
            detectionCount++;
            const time = new Date().toLocaleTimeString();
            const newRow = `
                <tr>
                    <td>${detectionCount}</td>
                    <td><img src="${imageUrl}" class="thumbnail"></td>
                    <td>${object}</td>
                    <td>${(confidence * 100).toFixed(2)}%</td>
                    <td>${time}</td>
                </tr>`;
            logTable.innerHTML = newRow + logTable.innerHTML;
        }

        async function detectObjects() {
            if (!video.srcObject) return;
            const predictions = await model.detect(video);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (predictions.length === 0) {
                resultText.innerText = "No objects detected.";
            }

            predictions.forEach(prediction => {
                ctx.beginPath();
                ctx.rect(...prediction.bbox);
                ctx.lineWidth = 3;
                ctx.strokeStyle = "red";
                ctx.fillStyle = "red";
                ctx.stroke();
                ctx.fillText(`${prediction.class} (${Math.round(prediction.score * 100)}%)`, prediction.bbox[0], prediction.bbox[1] - 10);

                resultText.innerText = `Detected: ${prediction.class} (${Math.round(prediction.score * 100)}%)`;

                const imageUrl = captureImage();
                logDetection(prediction.class, prediction.score, imageUrl);
            });
        }

        function toggleCamera() {
            if (cameraActive) {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                video.srcObject = null;
                cameraActive = false;
                resultText.innerText = "Camera is off.";
            } else {
                setupCamera();
                cameraActive = true;
                resultText.innerText = "Camera is on.";
                setInterval(detectObjects, 5000);
            }
        }

        // Event listener for touch to capture image
        video.addEventListener('click', () => {
            const imageUrl = captureImage();
            logDetection("Captured Image", 1, imageUrl);  // Log as a captured image
        });

        async function start() {
            await loadModel();
        }

        start();
    </script>
</body>
</html>
